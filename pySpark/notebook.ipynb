{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "israeli-glass",
   "metadata": {},
   "source": [
    "# Football Twitter Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-quarter",
   "metadata": {},
   "source": [
    "## Imports the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flying-naples",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-67f60937cd1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStructField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoubleType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLongType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import lit, explode, split, col, from_json, to_json, json_tuple, window, struct, udf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-effect",
   "metadata": {},
   "source": [
    "## Set Up Spark Session and Define Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "colored-moment",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparkSession' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-81428f667514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wordCounter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Defines schema of Twitter Post\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtweetSchema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"payload\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparkSession' is not defined"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"wordCounter\").getOrCreate()\n",
    "\n",
    "# Defines schema of Twitter Post\n",
    "tweetSchema = StructType() \\\n",
    "    .add(\"payload\", StringType())\n",
    "\n",
    "payloadSchema = StructType() \\\n",
    "    .add(\"Text\", StringType()) \\\n",
    "    .add(\"Lang\", StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-minister",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts structured content from json tweet message\n",
    "def extractTweetPayload(df, tweetSchema, payloadSchema):\n",
    "    return df \\\n",
    "        .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"CAST(timestamp AS TIMESTAMP)\", \"offset\") \\\n",
    "        .withColumn(\"data\", from_json(\"value\", tweetSchema)) \\\n",
    "        .withColumn(\"payload\", from_json(\"data.payload\", payloadSchema)) \\\n",
    "        .select(\"payload.*\", \"key\", \"timestamp\")\n",
    "\n",
    "\n",
    "def getLastName(full_name):\n",
    "    return full_name.split(\" \")[-1:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-edgar",
   "metadata": {},
   "source": [
    "## Streaming Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sticky-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCountQuery(df, colName):\n",
    "    return df \\\n",
    "        .withWatermark(\"timestamp\", \"10 seconds\") \\\n",
    "        .withColumn('word', explode(split(col(colName), ' '))) \\\n",
    "        .groupBy(window(col(\"timestamp\"), \"10 seconds\", \"5 seconds\"),\n",
    "                 col('word')\n",
    "                 ).count() \\\n",
    "        .select(\"word\", \"count\", to_json(struct(\"word\", \"count\")).alias(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exempt-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langCountQuery(df, colName):\n",
    "    return df \\\n",
    "        .withWatermark(\"timestamp\", \"2 minutes\") \\\n",
    "        .groupBy(\n",
    "            window(col(\"timestamp\"), \"2 minutes\", \"1 minutes\"),\n",
    "            col(colName)\n",
    "        ).count() \\\n",
    "        .select(colName, \"count\", to_json(struct(colName, \"count\")).alias(\"value\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-metropolitan",
   "metadata": {},
   "source": [
    "## Static Dataset Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"players_21.csv\")\n",
    "\n",
    "lastNameUDF = udf(getLastName, StringType())\n",
    "\n",
    "player_names = players \\\n",
    "    .withColumn(\n",
    "        \"word\", lastNameUDF(\"short_name\")) \\\n",
    "    .withColumn(\"category\", lit(\"Player\")) \\\n",
    "    .select(\"word\", \"category\") \\\n",
    "    .limit(500) \\\n",
    "\n",
    "teams = players \\\n",
    "    .select(\"club_name\") \\\n",
    "    .withColumn(\"category\", lit(\"Team\")) \\\n",
    "    .limit(500) \\\n",
    "    .dropDuplicates() \\\n",
    "\n",
    "topics = player_names.union(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-visit",
   "metadata": {},
   "source": [
    "# Streaming Queries Definition and Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the data from kafka\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .option(\"subscribe\", \"tweets\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "messages = extractTweetPayload(df, tweetSchema, payloadSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = wordCountQuery(messages, \"Text\") \\\n",
    "    .join(topics, \"word\") \\\n",
    "    .select(\"word\", \"count\",\"category\", to_json(struct(\"word\", \"count\",\"category\")).alias(\"value\"))\n",
    "\n",
    "query = wordCount \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"checkpointLocation\", \"/home/alessandro/Desktop/Repos/Football-Twitter-Streaming/checkpoints\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"topic\", \"countByName\") \\\n",
    "    .start()\n",
    "'\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "langCount = langCountQuery(messages, \"Lang\")\n",
    "\n",
    "query = wordCount \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"checkpointLocation\", \"/home/alessandro/Desktop/Repos/Football-Twitter-Streaming/checkpoints\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"topic\", \"countByLang\") \\\n",
    "    .start()\n",
    "'\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
